{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.stats._stats import _kendall_dis\n",
    "import statistics\n",
    "import time\n",
    "# import warnings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics\n",
    "def top_n_accuracy(pred_val, gt_val, n: int):\n",
    "    tmp_pred = pred_val.copy()\n",
    "    tmp_gt_val = gt_val.copy()\n",
    "    tmp_pred.sort(key=lambda element: element[1], reverse=True)\n",
    "    tmp_gt_val.sort(key=lambda element: element[1], reverse=True)\n",
    "    \n",
    "    pred, gt = [], []\n",
    "    for i in range(int(len(tmp_pred)*n/100)):\n",
    "        pred.append(tmp_pred[i][0])\n",
    "        gt.append(tmp_gt_val[i][0])\n",
    "    \n",
    "    return float(len(set(gt)&set(pred)) / len(pred))\n",
    "\n",
    "def Kendall_tau_distance(pred_val, gt_val):\n",
    "    pred_bc_val, gt_bc_val = [], []\n",
    "    for i in pred_val:\n",
    "        pred_bc_val.append(i[1])\n",
    "    for i in gt_val:\n",
    "        gt_bc_val.append(i[1])\n",
    "\n",
    "    tau, _ = stats.kendalltau(pred_bc_val, gt_bc_val)\n",
    "    \n",
    "    return float(tau)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('./BeBeCA/Source_Code/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/lin-chia/Desktop/BeBeCA/Source_Code'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 處理資料格式讓其符合kbc的input"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    data_path = '../../hw1_data/Synthetic/5000/' + str(i) + '.txt'\n",
    "    out_data_path = '../../hw1_data/Synthetic/5000/kbc_data/' + str(i) + '.txt'\n",
    "    f_graph = open(data_path, mode='r')\n",
    "    tmp_src, tmp_tgt = [], []\n",
    "    for line in f_graph:\n",
    "        src, tgt = line.split()\n",
    "        # print(src, tgt)\n",
    "        tmp_src.append(src)\n",
    "        tmp_tgt.append(tgt)\n",
    "    f_graph.close()\n",
    "    edges = len(tmp_src)\n",
    "    out_f_graph = open(out_data_path, mode='w')\n",
    "    out_f_graph.writelines(\"5000 \"+str(edges)+\"\\n\")\n",
    "    for i in range(edges):\n",
    "        out_f_graph.writelines(tmp_src[i]+' '+tmp_tgt[i]+\"\\n\")\n",
    "    out_f_graph.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Computing betweenness centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_clock_time_list = []\n",
    "for i in range(30):\n",
    "    t0 = time.time()\n",
    "    input_file = '../../hw1_data/Synthetic/5000/kbc_data/'+str(i)+'.txt'\n",
    "    output_file = '../../baseline_model/k_bc/Synthetic/'+str(i)+'_score.txt'\n",
    "    cmd = './KPATH 4 '+input_file+ ' '+output_file\n",
    "    os.system(cmd)\n",
    "    wall_clock_time = time.time() - t0\n",
    "    wall_clock_time_list.append(wall_clock_time)\n",
    "    \n",
    "print('avg excute time',sum(wall_clock_time_list)/len(wall_clock_time_list))\n",
    "print('stdev excute time',statistics.stdev(wall_clock_time_list))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real-world data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../hw1_data/youtube/com-youtube.txt'\n",
    "score_path = '../../hw1_data/youtube/com-youtube_score.txt'\n",
    "out_data_path = '../../hw1_data/youtube/kbc_data/com-youtube.txt'\n",
    "\n",
    "# Get number of nodes.\n",
    "f_score = open(score_path, mode='r')\n",
    "node = []\n",
    "for line in f_score:\n",
    "    tmp_node, _ = line.split(':')\n",
    "    node.append(tmp_node)\n",
    "f_score.close()\n",
    "nodes = len(node)\n",
    "\n",
    "# Get number of edges.\n",
    "f_graph = open(data_path, mode='r')\n",
    "tmp_src, tmp_tgt = [], []\n",
    "for line in f_graph:\n",
    "    src, tgt = line.split()\n",
    "    # print(src, tgt)\n",
    "    tmp_src.append(src)\n",
    "    tmp_tgt.append(tgt)\n",
    "f_graph.close()\n",
    "edges = len(tmp_src)\n",
    "\n",
    "# write a new data for k-bc running data.\n",
    "out_f_graph = open(out_data_path, mode='w')\n",
    "out_f_graph.writelines(str(nodes)+\" \"+str(edges)+\"\\n\")\n",
    "for i in range(edges):\n",
    "    out_f_graph.writelines(tmp_src[i]+' '+tmp_tgt[i]+\"\\n\")\n",
    "out_f_graph.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Computing betweenness centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excute time:  127602.76922130585\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "input_file = '../../hw1_data/youtube/kbc_data/com-youtube.txt'\n",
    "output_file = '../../baseline_model/k_bc/Youtube/com-youtube_score.txt'\n",
    "cmd = './KPATH 4 '+input_file+ ' '+output_file\n",
    "os.system(cmd)\n",
    "wall_clock_time = time.time() - t0\n",
    "    \n",
    "print('excute time: ', wall_clock_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-1%: 0.9953333333333334 +- 0.008603661343041535\n",
      "top-5%: 0.9889333333333336 +- 0.004540494681642412\n",
      "top-10%: 0.9864666666666665 +- 0.0027131014614698613\n",
      "kendall tau disance: 0.9718834646929385 +- 0.0011523943180940996 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "top1_list = []\n",
    "top5_list = []\n",
    "top10_list = []\n",
    "kendall_ist = []\n",
    "for i in range(30):\n",
    "    pred_val_path = '../../baseline_model/k_bc/Synthetic/' + str(i) + '_score.txt'\n",
    "    gt_val_path = '../../hw1_data/Synthetic/5000/' + str(i) + '_score.txt'\n",
    "    f_pred = open(pred_val_path, mode='r')\n",
    "    f_gt = open(gt_val_path, mode='r')\n",
    "\n",
    "    pred_list, gt_list = [], []\n",
    "    for line in f_pred:\n",
    "        ind, _ = line.split(':')\n",
    "        _, score = line.split()\n",
    "        pred_list.append([int(ind), float(score)])\n",
    "\n",
    "    for line in f_gt:\n",
    "        ind, score = line.split()\n",
    "        gt_list.append([int(ind), float(score)])\n",
    "    f_pred.close()\n",
    "    f_gt.close()\n",
    "    top1_list.append(top_n_accuracy(pred_list, gt_list, 1))\n",
    "    top5_list.append(top_n_accuracy(pred_list, gt_list, 5))\n",
    "    top10_list.append(top_n_accuracy(pred_list, gt_list, 10))\n",
    "    kendall_ist.append(Kendall_tau_distance(pred_list, gt_list))\n",
    "\n",
    "print(\"top-1%:\", sum(top1_list) / len(top1_list),'+-',statistics.stdev(top1_list))\n",
    "print(\"top-5%:\", sum(top5_list) / len(top5_list),'+-',statistics.stdev(top5_list))\n",
    "print(\"top-10%:\", sum(top10_list) / len(top10_list),'+-',statistics.stdev(top10_list))\n",
    "print(\"kendall tau disance:\",sum(kendall_ist) / len(kendall_ist),'+-',statistics.stdev(kendall_ist),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lin-chia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
